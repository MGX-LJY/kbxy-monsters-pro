# -*- coding: utf-8 -*-
# KBXY è·å–æ¸ é“æ¸…æ´—å°ï¼ˆUIï¼‰
# è¿è¡Œï¼š streamlit run tools_ui.py

import re
import io
import os
import json
import time
import base64
import pandas as pd
import streamlit as st

st.set_page_config(page_title="KBXY è·å–æ¸ é“æ¸…æ´—å°", layout="wide")

# --------------------- é€šç”¨æ­£åˆ™ä¸å¸¸é‡ ---------------------
LOG_RE = re.compile(
    r"^\s*(?:INFO|WARNING|ERROR)?\s*ACQ\s+"
    r"(?P<name>.*?)\s*\|\s*type=(?P<type>[^|]+?)\s+new=(?P<new>\S+)\s*\|\s*method=(?P<method>.*)\s*$"
)

OTHERS = {"å…¶å®ƒ", "å…¶ä»–", "None", "null", "NULL", "", None}

DEFAULT_RULES_TXT = """# ä¸€è¡Œä¸€æ¡ï¼šPythonæ­£åˆ™  =>  æ ‡ç­¾ï¼ˆå‘½ä¸­åç«‹å³è¿”å›ï¼Œä¸å†ç»§ç»­åŒ¹é…ï¼‰
# å¯ç”¨æ ‡ç­¾ï¼šæ´»åŠ¨è·å–å® ç‰© / BOSSå® ç‰© / å…‘æ¢/å•†åº— / å¯æ•æ‰å® ç‰© / è¶…è¿›åŒ– / ä»»åŠ¡è·å– / å…¶å®ƒ
# ç¤ºä¾‹ï¼ˆå¯æŒ‰éœ€ä¿®æ”¹/è¿½åŠ /è°ƒåºï¼‰ï¼š
(å‚ä¸|è¿›è¡Œ).{0,8}(æ´»åŠ¨|å……å€¼å¥½ç¤¼|ä¸ƒæ—¥é€å¥½ç¤¼|å˜‰å¹´å|èŠ‚|åˆä¸€|å®ˆ|æˆ˜|æŒ‘æˆ˜æ´»åŠ¨|è€ƒéªŒ).*(è·|å¯?è·å¾—) => æ´»åŠ¨è·å–å® ç‰©
(BOSS|é¦–é¢†|åœ°åºœ|å†…æ®¿|ä¸‡å¦–æ´|å‰¯æœ¬|ç»„é˜Ÿ|æŒ‘æˆ˜|åˆ‡ç£‹|é€šå…³|è£è€€|å¹»å¢ƒ|è¶…èƒ½å¹»å¢ƒ|é¦–æ¬¡(å‡»|æ‰“)è´¥) => BOSSå® ç‰©
(å¯»å®ç½—ç›˜|ç½—ç›˜|ä¸ƒæ˜Ÿå®å›¾|åŒ—æ–—ä¸ƒæ˜Ÿå›¾|ç¥å® ä¹‹é­‚|æ‰­è›‹|è½¬ç›˜|å…‘æ¢æ‰€|ç¤¼ç›’|å•†åº—).*(è·|å¯?è·å¾—|æŠ½(å–|å¾—)) => å…‘æ¢/å•†åº—
(å¯åœ¨.*æ•è·|æ•æ‰|æ•è·|æœ‰å‡ ç‡?è·å¾—|åœ¨.*(æµ·å²¸|å±±|å›½|åŒºåŸŸ|åœ°ç‚¹|æ´|è°·|æ—|æ¹¾)) => å¯æ•æ‰å® ç‰©
(è¶…è¿›åŒ–|è¿›åŒ–|è§‰é†’|è¿›é˜¶|å‡é˜¶|æ— åŒå°è®°|æ— åŒçŠ¶æ€|æˆ˜æ–—ä¸­å‡ºç°) => è¶…è¿›åŒ–
(ä»»åŠ¡|å‰§æƒ…|ç‚¹äº®|ç­¾åˆ°|æ¯æ—¥|å‘¨å¸¸) => ä»»åŠ¡è·å–
(VIP|å¹´è´¹|æœˆè´¹|å……å€¼|æˆä¸º.*è¶…çº§VIP|å½“æœˆVIP) => å…¶å®ƒ
"""

ACQ_LABELS = ["æ´»åŠ¨è·å–å® ç‰©", "BOSSå® ç‰©", "å…‘æ¢/å•†åº—", "å¯æ•æ‰å® ç‰©", "è¶…è¿›åŒ–", "ä»»åŠ¡è·å–", "å…¶å®ƒ"]


# --------------------- å·¥å…·å‡½æ•° ---------------------
def _clean(x: str) -> str:
    if x is None:
        return ""
    return re.sub(r"\s+", " ", str(x)).strip()


def parse_log_text(text: str) -> list[dict]:
    """ä» ACQ æ—¥å¿—è¡Œè§£æç»“æ„"""
    items = []
    for i, line in enumerate(text.splitlines(), 1):
        m = LOG_RE.match(line)
        if not m:
            continue
        typ = _clean(m.group("type"))
        items.append(
            {
                "name": _clean(m.group("name")),
                "type": typ.replace("å…¶å®ƒ", "å…¶ä»–") if typ else typ,
                "new": _clean(m.group("new")),
                "method": _clean(m.group("method")),
                "source": "log",
                "line_no": i,
            }
        )
    return items


def parse_json_text(text: str) -> list[dict]:
    """ä» JSON ä¸­æŠ½å– name/type/new/methodï¼Œå…è®¸ acq_ å‰ç¼€å­—æ®µå"""
    out = []
    try:
        data = json.loads(text)
    except Exception:
        return out

    def pick_one(d):
        name = d.get("name") or d.get("title") or ""
        typ = d.get("acq_type") or d.get("type")
        new = d.get("acq_new_type") or d.get("new_type") or d.get("new")
        method = d.get("acq_method") or d.get("method")
        if name or method or typ:
            out.append(
                {
                    "name": _clean(name),
                    "type": _clean(typ) if typ is not None else None,
                    "new": _clean(new),
                    "method": _clean(method),
                    "source": "json",
                    "line_no": None,
                }
            )

    if isinstance(data, list):
        for d in data:
            if isinstance(d, dict):
                pick_one(d)
    elif isinstance(data, dict):
        pick_one(data)
    return out


def load_inputs(uploaded_files: list, pasted_text: str) -> list[dict]:
    """åˆå¹¶ä¸Šä¼ æ–‡ä»¶ä¸ç²˜è´´æ–‡æœ¬"""
    items = []
    # æ–‡ä»¶
    for f in uploaded_files or []:
        content = f.read().decode("utf-8", errors="ignore")
        # å…ˆè¯• JSONï¼Œå†å›è½æ—¥å¿—
        js = parse_json_text(content)
        if js:
            items.extend(js)
        else:
            items.extend(parse_log_text(content))
    # ç²˜è´´
    pasted_text = pasted_text or ""
    if pasted_text.strip():
        js = parse_json_text(pasted_text)
        if js:
            items.extend(js)
        else:
            items.extend(parse_log_text(pasted_text))
    return items


def filter_others(items: list[dict]) -> list[dict]:
    """ä»…ä¿ç•™åŸå§‹ type å±äº 'å…¶å®ƒ/å…¶ä»–/None/ç©º' çš„æ¡ç›®"""
    out = []
    for it in items:
        typ = it.get("type")
        if typ in OTHERS or _clean(typ) in OTHERS:
            out.append(it)
    return out


def compile_rules(rules_text: str) -> list[tuple[re.Pattern, str]]:
    rules = []
    for ln in (rules_text or "").splitlines():
        ln = ln.strip()
        if not ln or ln.startswith("#"):
            continue
        if "=>" not in ln:
            continue
        patt, label = ln.split("=>", 1)
        patt = patt.strip()
        label = label.strip()
        if not patt or not label:
            continue
        try:
            rules.append((re.compile(patt), label))
        except re.error as e:
            st.warning(f"æ­£åˆ™ç¼–è¯‘å¤±è´¥ï¼š{patt} -> {e}")
    return rules


def reclassify(items: list[dict], rules: list[tuple[re.Pattern, str]]) -> list[dict]:
    """æŒ‰è§„åˆ™å¯¹ method é‡åˆ†ç±»ï¼ˆä»…å¯¹åŸå§‹ 'å…¶å®ƒ/ç©º'ï¼‰"""
    out = []
    for it in items:
        m = it.get("method") or ""
        label = "å…¶å®ƒ"
        for patt, lab in rules:
            if patt.search(m):
                label = lab
                break
        new_it = dict(it)
        new_it["suggest_type"] = label
        return_flag = None
        if re.search(r"(ç»ç‰ˆ|åœæ­¢(è·å–|äº§å‡º)|ä¸‹æ¶|å·²ç»“æŸ|æœªå¼€æ”¾|ä¸å¯è·å–|æ— æ³•è·å¾—)", m):
            return_flag = False
        elif re.search(r"(å¯æ•æ‰|é‡å¤–|å¸¸é©»|é•¿æœŸ|å‘¨å¸¸|æ—¥å¸¸|å…‘æ¢(é•¿æœŸ)?å¼€æ”¾|å•†åº—(é•¿æœŸ)?å¼€æ”¾|éšæ—¶å¯|ä»»æ„æ—¶æ®µ)", m):
            return_flag = True
        new_it["suggest_new"] = return_flag
        out.append(new_it)
    return out


def df_download_button(df: pd.DataFrame, label: str, file_name: str, file_type: str = "json"):
    if file_type == "json":
        data = df.to_json(orient="records", force_ascii=False, indent=2)
        mime = "application/json"
    else:
        data = df.to_csv(index=False)
        mime = "text/csv"
    st.download_button(label, data=data, file_name=file_name, mime=mime)


def gen_rules_snippet(rules: list[tuple[re.Pattern, str]]) -> str:
    """ç”Ÿæˆå¯è´´å›çˆ¬è™«çš„ ACQ_CLASS_RULES ä»£ç ç‰‡æ®µï¼ˆé¡ºåºä¿ç•™ï¼‰"""
    lines = ["ACQ_CLASS_RULES = ["]
    for patt, lab in rules:
        # è½¬ä¹‰å†…å±‚çš„åæ–œæ ä¸å¼•å·
        patt_src = patt.pattern.replace("\\", "\\\\").replace('"', '\\"')
        lab_src = lab.replace("\\", "\\\\").replace('"', '\\"')
        lines.append(f'    (r"{patt_src}", "{lab_src}"),')
    lines.append("]")
    return "\n".join(lines)


# --------------------- UI ---------------------
st.title("ğŸ›  KBXY è·å–æ¸ é“æ¸…æ´—å°ï¼ˆtype=å…¶å®ƒ ä¸“ç”¨ï¼‰")

with st.sidebar:
    st.header("è¾“å…¥")
    files = st.file_uploader("ä¸Šä¼ æ—¥å¿—æˆ–JSONï¼ˆå¯å¤šé€‰ï¼‰", type=["log", "txt", "json"], accept_multiple_files=True)
    pasted = st.text_area("æˆ–ç²˜è´´æ—¥å¿—/JSONå†…å®¹", height=180, placeholder="å¯ç›´æ¥æŠŠ INFO ACQ æ—¥å¿—æˆ– out_acq_xxx.json ç²˜è¿›æ¥")
    st.caption("æç¤ºï¼šJSON ä¼šä¼˜å…ˆè§£æï¼›å¦åˆ™æŒ‰æ—¥å¿—è¡Œè§£æã€‚")

    st.header("è§„åˆ™")
    rules_text = st.text_area("æ­£åˆ™ => æ ‡ç­¾ï¼ˆæŒ‰é¡ºåºåŒ¹é…ï¼‰", value=DEFAULT_RULES_TXT, height=240)
    st.caption("å‘½ä¸­ç¬¬ä¸€æ¡è§„åˆ™åç«‹å³ç¡®å®šæ ‡ç­¾ï¼›æœªå‘½ä¸­åˆ™ä¿æŒâ€œå…¶å®ƒâ€ã€‚")

    st.header("å¿«é€Ÿæœç´¢")
    q = st.text_input("åœ¨ name / method ä¸­æŸ¥æ‰¾", value="")

raw_items = load_inputs(files, pasted)
others = filter_others(raw_items)
rules = compile_rules(rules_text)
recl_items = reclassify(others, rules)

col_a, col_b, col_c = st.columns([1,1,2])
with col_a:
    st.metric("æ€»æ¡ç›®", len(raw_items))
with col_b:
    st.metric("å¾…æ¸…æ´—ï¼ˆåŸå§‹ type=å…¶å®ƒ/ç©ºï¼‰", len(others))

df = pd.DataFrame(recl_items)
if q.strip():
    q_re = re.compile(re.escape(q.strip()), re.I)
    mask = df.apply(lambda r: bool(q_re.search(_clean(r.get("name"))) or q_re.search(_clean(r.get("method")))), axis=1)
    df = df[mask]

st.subheader("é¢„è§ˆ")
if df.empty:
    st.info("æ²¡æœ‰å¯æ˜¾ç¤ºçš„æ•°æ®ã€‚è¯·ä¸Šä¼ æˆ–ç²˜è´´å†…å®¹ï¼Œæˆ–è§„åˆ™æœªå‘½ä¸­ã€‚")
else:
    show_cols = ["name", "type", "new", "method", "suggest_type", "suggest_new", "source", "line_no"]
    for c in show_cols:
        if c not in df.columns:
            df[c] = None
    st.dataframe(df[show_cols], use_container_width=True, height=420)

    c1, c2, c3, c4 = st.columns(4)
    with c1:
        df_download_button(df[show_cols], "â¬‡ï¸ å¯¼å‡º JSON", "others_reclassified.json", "json")
    with c2:
        df_download_button(df[show_cols], "â¬‡ï¸ å¯¼å‡º CSV", "others_reclassified.csv", "csv")
    with c3:
        st.download_button("ğŸ“‹ å¤åˆ¶ ACQ_CLASS_RULES ç‰‡æ®µ",
                           data=gen_rules_snippet(rules),
                           file_name="acq_class_rules.py",
                           mime="text/plain")
    with c4:
        st.write("")

# --------------------- æ­£åˆ™æµ‹è¯•å° ---------------------
st.markdown("---")
st.subheader("ğŸ” æ­£åˆ™æµ‹è¯•å°")
sample_methods = [it["method"] for it in others if it.get("method")]
sample_methods = list(dict.fromkeys(sample_methods))  # å»é‡ä¿åº
if not sample_methods:
    st.info("è¯·å…ˆå¯¼å…¥æ•°æ®ï¼›è¿™é‡Œä¼šæ˜¾ç¤ºåŸå§‹ type=å…¶å®ƒ çš„ method ä¾›æµ‹è¯•ã€‚")
else:
    s1, s2 = st.columns([2, 1])
    with s1:
        test_text = st.selectbox("é€‰ä¸€æ¡ method ä½œä¸ºæ ·æœ¬", options=sample_methods, index=0)
    with s2:
        test_patt = st.text_input("è¾“å…¥æ­£åˆ™ï¼ˆä¸´æ—¶æµ‹è¯•ï¼Œä¸å½±å“ä¸Šé¢çš„è§„åˆ™ï¼‰", value=r"(VIP|å¹´è´¹|æœˆè´¹|å……å€¼|è¶…çº§VIP|å½“æœˆVIP)")
    try:
        rx = re.compile(test_patt)
        m = rx.search(test_text or "")
        if m:
            st.success("âœ… å‘½ä¸­ï¼")
            st.code(f"åŒ¹é…ç‰‡æ®µï¼š{m.group(0)}", language="text")
        else:
            st.warning("æœªå‘½ä¸­ã€‚")
    except re.error as e:
        st.error(f"æ­£åˆ™é”™è¯¯ï¼š{e}")

# --------------------- è§„åˆ™å‘½ä¸­ç»Ÿè®¡ ---------------------
st.markdown("---")
st.subheader("ğŸ“Š è§„åˆ™å‘½ä¸­ç»Ÿè®¡ï¼ˆæŒ‰é¡ºåºï¼‰")
if rules and others:
    stats = []
    remained = list(others)
    for patt, lab in rules:
        cnt = sum(1 for it in remained if patt.search(it.get("method") or ""))
        stats.append({"label": lab, "pattern": patt.pattern, "hits": cnt})
        # ç§»é™¤å·²å‘½ä¸­ï¼Œæ¨¡æ‹Ÿâ€œç¬¬ä¸€æ¡å‘½ä¸­å³å½’ç±»â€
        remained = [it for it in remained if not patt.search(it.get("method") or "")]
    stats.append({"label": "å…¶å®ƒ(æœªå‘½ä¸­)", "pattern": "-", "hits": len(remained)})
    st.dataframe(pd.DataFrame(stats), use_container_width=True)
else:
    st.info("æš‚æ— æ•°æ®æˆ–è§„åˆ™ä¸ºç©ºã€‚")